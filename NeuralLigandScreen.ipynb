{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Installations\n",
    "!pip install -q condacolab\n",
    "import condacolab\n",
    "condacolab.install()\n",
    "!conda install -c conda-forge mamba -y\n",
    "!mamba install -q -y -c conda-forge pandas matplotlib seaborn rdkit\n",
    "!pip install --upgrade keras scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Complete Workflow\n",
    "from pathlib import Path\n",
    "from warnings import filterwarnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import MACCSkeys, Draw, rdFingerprintGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.models import Sequential, load_model, model_from_json\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "%matplotlib inline\n",
    "\n",
    "# Silence warnings\n",
    "filterwarnings(\"ignore\")\n",
    "\n",
    "# Function to convert SMILES to fingerprints\n",
    "def smiles_to_fp(smiles, method=\"maccs\", n_bits=2048):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if method == \"maccs\":\n",
    "        return np.array(MACCSkeys.GenMACCSKeys(mol))\n",
    "    elif method == \"morgan2\":\n",
    "        fpg = rdFingerprintGenerator.GetMorganGenerator(radius=2, fpSize=n_bits)\n",
    "        return np.array(fpg.GetCountFingerprint(mol))\n",
    "    elif method == \"morgan3\":\n",
    "        fpg = rdFingerprintGenerator.GetMorganGenerator(radius=3, fpSize=n_bits)\n",
    "        return np.array(fpg.GetCountFingerprint(mol))\n",
    "    else:\n",
    "        print(f\"Warning: Wrong method specified: {method}. Default used.\")\n",
    "        return np.array(MACCSkeys.GenMACCSKeys(mol))\n",
    "\n",
    "# Load and prepare data\n",
    "df = pd.read_csv(\"EGFR_compounds_new.csv\").reset_index(drop=True)\n",
    "chembl_df = df[[\"smiles\", \"pIC50\"]]\n",
    "chembl_df[\"fingerprints_df\"] = chembl_df[\"smiles\"].apply(smiles_to_fp)\n",
    "\n",
    "# Split data into training and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    chembl_df[\"fingerprints_df\"], chembl_df[[\"pIC50\"]], test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Define neural network model\n",
    "def neural_network_model(hidden1, hidden2):\n",
    "    model = Sequential([\n",
    "        Dense(hidden1, activation=\"relu\", name=\"layer1\"),\n",
    "        Dense(hidden2, activation=\"relu\", name=\"layer2\"),\n",
    "        Dense(1, activation=\"linear\", name=\"layer3\")\n",
    "    ])\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"mse\", \"mae\"])\n",
    "    return model\n",
    "\n",
    "# Neural network parameters\n",
    "batch_sizes = [16, 32, 64]\n",
    "nb_epoch = 50\n",
    "layer1_size = 64\n",
    "layer2_size = 32\n",
    "\n",
    "# Plot loss for different batch sizes\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.set(color_codes=True)\n",
    "for index, batch in enumerate(batch_sizes):\n",
    "    plt.subplot(1, len(batch_sizes), index + 1)\n",
    "    model = neural_network_model(layer1_size, layer2_size)\n",
    "    history = model.fit(\n",
    "        np.array(list(x_train)).astype(float), y_train.values,\n",
    "        batch_size=batch, validation_data=(np.array(list(x_test)).astype(float), y_test.values),\n",
    "        verbose=0, epochs=nb_epoch\n",
    "    )\n",
    "    plt.plot(history.history[\"loss\"], label=\"train\")\n",
    "    plt.plot(history.history[\"val_loss\"], label=\"test\")\n",
    "    plt.legend([\"train\", \"test\"], loc=\"upper right\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylim((0, 15))\n",
    "    plt.title(f\"test loss = {history.history['val_loss'][nb_epoch-1]:.2f}, batch size = {batch}\")\n",
    "plt.show()\n",
    "\n",
    "# Train model with best batch size (64) and save best weights\n",
    "model = neural_network_model(layer1_size, layer2_size)\n",
    "filepath = \"best_weights.weights.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor=\"loss\", verbose=0, save_best_only=True, mode=\"min\", save_weights_only=True)\n",
    "callbacks_list = [checkpoint]\n",
    "model.fit(np.array(list(x_train)).astype(float), y_train.values, epochs=nb_epoch, batch_size=64, callbacks=callbacks_list, verbose=0)\n",
    "\n",
    "# Save model to JSON and weights to HDF5\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"model.weights.h5\")\n",
    "\n",
    "# Evaluate model\n",
    "scores = model.evaluate(np.array(list(x_test)), y_test.values, verbose=0)\n",
    "print(f\"Evaluate the model on the test data\\n loss: {scores[0]:.2f}\\n mse: {scores[1]:.2f}\\n mae: {scores[2]:.2f}\")\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = model.predict(np.array(list(x_test)))\n",
    "print(\"\\nFirst 5 predicted pIC50 values:\")\n",
    "[print(f\"{value[0]:.2f}\") for value in y_pred[:5]]\n",
    "\n",
    "# Scatter plot of predicted vs true values\n",
    "plt.figure()\n",
    "plt.scatter(y_pred, y_test, marker=\".\")\n",
    "lin = np.linspace(0, 15, 100)\n",
    "plt.plot(lin, lin)\n",
    "plt.gca().set_aspect(\"equal\", adjustable=\"box\")\n",
    "plt.xlabel(\"Predicted values\")\n",
    "plt.ylabel(\"True values\")\n",
    "plt.title(\"Scatter plot: pIC50 values\")\n",
    "plt.xlim((0, 15))\n",
    "plt.ylim((0, 15))\n",
    "plt.show()\n",
    "\n",
    "# Load and predict on external data\n",
    "external_data = pd.read_csv(\"test.csv\").reset_index(drop=True)\n",
    "external_data[\"fingerprints_df\"] = external_data[\"canonical_smiles\"].apply(smiles_to_fp)\n",
    "\n",
    "# Load model and predict\n",
    "json_file = open(\"model.json\", \"r\")\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "model.load_weights(\"model.weights.h5\")\n",
    "predictions = model.predict(np.array(list(external_data[\"fingerprints_df\"])).astype(float), callbacks=callbacks_list)\n",
    "\n",
    "# Save predictions\n",
    "predicted_pIC50_df = external_data.join(pd.DataFrame(predictions, columns=[\"predicted_pIC50\"]))\n",
    "predicted_pIC50_df.to_csv(\"predicted_pIC50_df.csv\")\n",
    "\n",
    "# Select and display top 3 compounds\n",
    "top3_drug = predicted_pIC50_df.nlargest(3, \"predicted_pIC50\")\n",
    "mols_EGFR = [Chem.MolFromSmiles(smile) for smile in top3_drug[\"canonical_smiles\"]]\n",
    "pIC50_values = [f\"pIC50 value: {value:.2f}\" for value in top3_drug[\"predicted_pIC50\"]]\n",
    "Draw.MolsToGridImage(mols_EGFR, molsPerRow=3, subImgSize=(450, 300), legends=pIC50_values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
